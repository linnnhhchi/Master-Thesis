# -*- coding: utf-8 -*-
"""CNN-LSTM training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13-IKl6hX-5GPGPQ9llznxshQ6ruIZ8O0
"""

import random
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import tensorflow as tf
from keras import backend as K
from keras.models import Model, Sequential
from keras.layers import Input, LSTM, Conv1D, Dropout, Dense, Embedding, Flatten, RepeatVector, Concatenate
from keras.callbacks import EarlyStopping
from keras.optimizers import Adam, SGD, RMSprop
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

random.seed(404)
tf.random.set_seed(404)

"""**CNN-LSTM With Spatial Features**"""

df = pd.read_csv('/content/feature_data.csv')
df["date"] = pd.to_datetime(df["date"], infer_datetime_format=True, errors='coerce')
df.set_index('date', inplace=True)

X = df.drop(columns=['charged_energy'])
y = df['charged_energy']

# Encode land_types
label_encoder = LabelEncoder()
X['land_types'] = label_encoder.fit_transform(X['land_types'].astype(str))
X_land = np.array(X['land_types'], dtype=np.int32).reshape(-1, 1)  # reshaped for model input
X = X.drop(columns=['land_types'])

# Split data
train_size = int(len(X) * 0.8)
val_size = int(len(X) * 0.1)
test_size = len(X) - train_size - val_size

X_train, X_val, X_test = X[:train_size], X[train_size:train_size + val_size], X[train_size + val_size:]
y_train, y_val, y_test = y[:train_size], y[train_size:train_size + val_size], y[train_size + val_size:]
X_land_train, X_land_val, X_land_test = X_land[:train_size], X_land[train_size:train_size + val_size], X_land[train_size + val_size:]

# Feature types
numeric_features = ['year', 'temperature', 'dewpoint', 'road_density', 'commercial_density',
                    'residential_density', 'recreation_density', 'highway_proximity',
                    'public_transport_proximity', 'evcs_proximity', 'center_proximity',
                    'parking_density', 'month_sin', 'month_cos', 'hour_sin', 'hour_cos']
binary = ['day_of_week', 'weekend', 'holiday', 'covid', 'time_slot']

for col in binary:
    X[col] = X[col].astype(str)

# Preprocessor
preprocessor = ColumnTransformer(transformers=[
    ('num', MinMaxScaler(), numeric_features),
    ('cat', OneHotEncoder(handle_unknown='ignore'), binary)])

X_train = preprocessor.fit_transform(X_train, y_train)
X_val = preprocessor.transform(X_val)
X_test = preprocessor.transform(X_test)

X_train_seq = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))
X_val_seq = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))
X_test_seq = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))

X_train_seq = np.array(X_train_seq, dtype=np.float32)
X_val_seq = np.array(X_val_seq, dtype=np.float32)
X_test_seq = np.array(X_test_seq, dtype=np.float32)

y_train = np.array(y_train, dtype=np.float32)
y_val = np.array(y_val, dtype=np.float32)
y_test = np.array(y_test, dtype=np.float32)

best_params = {
    'filters': 208,
    'kernel_size': 5,
    'lstm_units': 96,
    'dropout': 0.2,
    'learning_rate': 0.0007,
    'optimizer': 'adam'}

if best_params['optimizer'] == "adam":
    optimizer = Adam(learning_rate=best_params['learning_rate'])
elif best_params['optimizer'] == "sgd":
    optimizer = SGD(learning_rate=best_params['learning_rate'])
else:
    optimizer = RMSprop(learning_rate=best_params['learning_rate'])

filters = best_params["filters"]
kernel_size = best_params["kernel_size"]
lstm_units = best_params["lstm_units"]
dropout_rate = best_params["dropout"]
optimizer_name = best_params["optimizer"]
learning_rate = best_params["learning_rate"]

seq_input = Input(shape=(X_train_seq.shape[1], 1), name='seq_input')
land_input = Input(shape=(1,), dtype='int32', name='land_input')

emb = Embedding(input_dim=np.max(X_land) + 1, output_dim=5)(land_input)
emb = Flatten()(emb)
emb = RepeatVector(X_train_seq.shape[1])(emb)

x = Concatenate()([seq_input, emb])
x = Conv1D(filters=filters // 2, kernel_size=kernel_size, activation='relu', padding='same')(x)
x = Dropout(dropout_rate)(x)
x = Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', padding='same')(x)
x = Dropout(dropout_rate)(x)
x = LSTM(units=lstm_units, activation='relu')(x)
output = Dense(1)(x)

model = Model(inputs=[seq_input, land_input], outputs=output)
model.compile(loss='mae', optimizer=optimizer)
model.summary()

early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

history = model.fit([X_train_seq, X_land_train], y_train,
                    validation_data=([X_val_seq, X_land_val], y_val),
                    epochs=30, batch_size=64, verbose=0,
                    callbacks=[early_stopping])

y_val_pred = model.predict([X_val_seq, X_land_val], batch_size=64)
y_test_pred = model.predict([X_test_seq, X_land_test], batch_size=64)

val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))
val_mae = mean_absolute_error(y_val, y_val_pred)
val_r2 = r2_score(y_val, y_val_pred)

test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))
test_mae = mean_absolute_error(y_test, y_test_pred)
test_r2 = r2_score(y_test, y_test_pred)

print(f'Spatial CNN-LSTM Validation:\n MAE: {val_mae:.4f} \n RMSE: {val_rmse:.4f} \n R-squared: {val_r2:.4f}')
print(f'Spatial CNN-LSTM Test:\n MAE: {test_mae:.4f} \n RMSE: {test_rmse:.4f} \n R-squared: {test_r2:.4f}')

test_dates = df.index[train_size + val_size:]
compare = pd.DataFrame({
    'charged_energy': y_test.flatten(),
    'predicted': y_test_pred.flatten()}, index=test_dates)

# Group by day
compare['day'] = compare.index.normalize()
group = compare.groupby('day')[['charged_energy', 'predicted']].sum().reset_index()
group['mae'] = np.abs(group['charged_energy'] - group['predicted'])

fig, axs = plt.subplots(2, 1, figsize=(12, 6), layout='constrained')

# Actual vs Predicted
axs[0].plot(group['day'], group['charged_energy'], label='Actual', color='blue')
axs[0].plot(group['day'], group['predicted'], label='Predicted', color='orange')
axs[0].set_title('SpatioTemporal LSTM: Actual vs Predicted')
axs[0].set_ylabel('Energy Consumption (kWh)')
axs[0].legend()
axs[0].grid(True)
axs[0].xaxis.set_major_locator(mdates.MonthLocator())
axs[0].xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))
axs[0].tick_params(labelbottom=False)

# Daily MAE
axs[1].plot(group['day'], group['mae'], label='MAE', color='purple')
axs[1].set_xlabel('Date')
axs[1].set_ylabel('Error Score')
axs[1].legend()
axs[1].grid(True)
axs[1].xaxis.set_major_locator(mdates.MonthLocator())
axs[1].xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))
axs[1].tick_params(axis='x', rotation=0)

plt.tight_layout()
plt.savefig('spatiotemporal_cnnlstm.png', dpi=300)
plt.show()

group['day'] = pd.to_datetime(group['day'])
group['month'] = group['day'].dt.month
group = group[(group['month'] >= 6) & (group['month'] <= 10)]

plt.figure(figsize=(10, 6))
sns.histplot(group['mae'], bins=30, kde=True, edgecolor='black', alpha=0.7)
plt.title('Residuals Histogram with KDE (After June)')
plt.xlabel('Residuals (MAE)')
plt.ylabel('Frequency')
plt.grid(True)
plt.savefig('spatial_cnnlstm_residuals.png', dpi=300)
plt.show()

land_labels = label_encoder.inverse_transform(X_land_test.flatten())

test_data = pd.DataFrame({
    'charged_energy': y_test.flatten(),
    'predicted': y_test_pred.flatten(),
    'land_types': land_labels
}, index=df.index[-len(y_test):])  # assuming y_test is the last slice

# Add hour column
test_data['hour'] = test_data.index.hour

# Filter specific land types
land_types_to_plot = ['commercial', 'construction']
filtered = test_data[test_data['land_types'].isin(land_types_to_plot)]

# Group by hour and land_types
group_hourly = (filtered.groupby(['hour', 'land_types'])[['charged_energy', 'predicted']]
                .sum().reset_index())
group_hourly['mae'] = np.abs(group_hourly['charged_energy'] - group_hourly['predicted'])

# Plotting
fig, axs = plt.subplots(2, 2, figsize=(12, 6), sharex=True)
for i, land in enumerate(land_types_to_plot):
    subset = group_hourly[group_hourly['land_types'] == land]

    axs[0, i].plot(subset['hour'], subset['charged_energy'], label='Actual', marker='o', color='blue')
    axs[0, i].plot(subset['hour'], subset['predicted'], label='Predicted', marker='x', color='orange')
    axs[0, i].set_title(f"{land.capitalize()}")
    axs[0, i].set_xlim(0, 24)
    axs[0, i].set_xticks(np.arange(0, 25, 1))
    if i == 0:
        axs[0, i].set_ylabel('Energy Consumption (kWh)')

    axs[0, i].legend()
    axs[0, i].grid(True)

    axs[1, i].plot(subset['hour'], subset['mae'], label='MAE', marker='o', color='purple')
    axs[1, i].set_xlabel('Hour')
    axs[1, i].set_xlim(0, 24)
    axs[1, i].set_xticks(np.arange(0, 25, 1))

    if i == 0:
        axs[1, i].set_ylabel('Error Score')
    axs[1, i].legend()
    axs[1, i].grid(True)

plt.tight_layout()
plt.savefig('spatiotemporal_cnnlstm_by_hour_day.png', dpi=300)
plt.show()

def get_all_feature_names(preprocessor):
    feature_names = []

    # Numeric features
    num_features = preprocessor.transformers_[0][2]
    feature_names.extend(num_features)

    # One-hot encoded binary features
    cat_encoder = preprocessor.transformers_[1][1]
    cat_features = preprocessor.transformers_[1][2]
    cat_feature_names = cat_encoder.get_feature_names_out(cat_features)
    feature_names.extend(cat_feature_names)

    return feature_names

X_test_aux = X_land_test
baseline_mae = test_mae  # from earlier evaluation
n_features = X_test_seq.shape[1]

importance_scores = []

# Permute each sequential feature
for i in range(n_features):
    X_permuted = X_test_seq.copy()
    X_permuted[:, i, 0] = np.random.permutation(X_permuted[:, i, 0])

    y_pred_permuted = model.predict([X_permuted, X_test_aux], batch_size=64, verbose=0)
    permuted_mae = mean_absolute_error(y_test, y_pred_permuted)

    importance = permuted_mae - baseline_mae
    importance_scores.append(importance)

# Permute land_type input
X_aux_permuted = X_test_aux.copy()
X_aux_permuted[:, 0] = np.random.permutation(X_aux_permuted[:, 0])

y_pred_permuted = model.predict([X_test_seq, X_aux_permuted], batch_size=64, verbose=0)
permuted_mae = mean_absolute_error(y_test, y_pred_permuted)

importance = permuted_mae - baseline_mae
importance_scores.append(importance)

# Convert to NumPy array
importance_scores = np.array(importance_scores)

# Feature names
all_feature_names = get_all_feature_names(preprocessor)
all_feature_names.append("land_type")

# Top 10 features
top_indices = np.argsort(importance_scores)[-10:][::-1]
top_scores = importance_scores[top_indices]
top_feature_names = [all_feature_names[i] for i in top_indices]

# Percentage contribution
total_importance = np.sum(importance_scores)
importance_percentages = (importance_scores / total_importance) * 100
top_percentages = importance_percentages[top_indices]

# Plot
plt.figure(figsize=(10, 6))
plt.barh(range(len(top_percentages)), top_percentages)
plt.yticks(range(len(top_percentages)), top_feature_names)
plt.xlabel("Permutation Importance (%)")
plt.title("Top 10 Permutation Feature Importances (CNN-LSTM)")
plt.gca().invert_yaxis()
plt.tight_layout()
plt.savefig('feature_importance_cnnlstm.png', dpi=300)
plt.show()

"""**CNN-LSTM Without Spatial**"""

df = pd.read_csv('/content/feature_data.csv')
df["date"] = pd.to_datetime(df["date"], infer_datetime_format=True, errors='coerce')
df.set_index('date', inplace=True)

X = df.drop(columns=['charged_energy', 'road_density', 'highway_proximity',
       'commercial_density', 'residential_density',
       'public_transport_proximity', 'evcs_proximity', 'parking_density',
       'recreation_density', 'center_proximity', 'land_types'])
y = df['charged_energy']

# Split data
train_size = int(len(X) * 0.8)
val_size = int(len(X) * 0.1)

X_train, X_val, X_test = X[:train_size], X[train_size:train_size + val_size], X[train_size + val_size:]
y_train, y_val, y_test = y[:train_size], y[train_size:train_size + val_size], y[train_size + val_size:]

# Feature types
numeric_features = ['temperature', 'dewpoint', 'year', 'hour_sin', 'hour_cos','month_sin', 'month_cos']
binary = ['day_of_week', 'weekend', 'holiday', 'covid', 'time_slot']

for col in binary:
    X[col] = X[col].astype(str)

preprocessor = ColumnTransformer(transformers=[
    ('num', MinMaxScaler(), numeric_features),
    ('cat', OneHotEncoder(handle_unknown='ignore'), binary)])

X_train = preprocessor.fit_transform(X_train, y_train)
X_val = preprocessor.transform(X_val)
X_test = preprocessor.transform(X_test)

X_train_seq_without = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))
X_val_seq_without = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))
X_test_seq_without = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))

X_train_seq_without = np.array(X_train_seq_without, dtype=np.float32)
X_val_seq_without = np.array(X_val_seq_without, dtype=np.float32)
X_test_seq_without = np.array(X_test_seq_without, dtype=np.float32)

y_train_without = np.array(y_train, dtype=np.float32)
y_val_without = np.array(y_val, dtype=np.float32)
y_test_without = np.array(y_test, dtype=np.float32)

best_params = {
    "filters": 128,
    "kernel_size": 3,
    "lstm_units": 192,
    "dropout": 0.2,
    "learning_rate": 0.0003,
    "optimizer": "adam"}

filters = best_params['filters']
kernel_size = best_params['kernel_size']
lstm_units = best_params['lstm_units']
dropout_rate = best_params['dropout']
learning_rate = best_params['learning_rate']
optimizers = best_params['optimizer']

if optimizers == "adam":
    optimizers = Adam(learning_rate=learning_rate)
elif optimizers == "sgd":
    optimizers = SGD(learning_rate=learning_rate)
else:
    optimizers = RMSprop(learning_rate=learning_rate)
    optimizer = RMSprop(learning_rate=learning_rate)

model = Sequential()
model.add(Input(shape=(X_train_seq_without.shape[1], X_train_seq_without.shape[2])))
model.add(Conv1D(filters=filters// 2, kernel_size=kernel_size, activation='relu', padding='same'))
model.add(Dropout(rate=dropout_rate))
model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', padding='same'))
model.add(Dropout(rate=dropout_rate))
model.add(LSTM(units=lstm_units, activation='relu', return_sequences=False))
model.add(Dense(1))
model.compile(loss='mae', optimizer=optimizers)
model.summary()

early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

history = model.fit(X_train_seq_without, y_train_without,
                        validation_data=(X_val_seq_without, y_val_without),
                        epochs=30, batch_size=32,
                        callbacks=[early_stopping], verbose=0)

y_val_pred_without = model.predict(X_val_seq_without, batch_size=32)
y_test_pred_without = model.predict(X_test_seq_without, batch_size=32)

val_rmse_without = np.sqrt(mean_squared_error(y_val_without, y_val_pred_without))
val_mae_without = mean_absolute_error(y_val_without, y_val_pred_without)
val_r2_without = r2_score(y_val_without, y_val_pred_without)

test_rmse_without = np.sqrt(mean_squared_error(y_test_without, y_test_pred_without))
test_mae_without = mean_absolute_error(y_test_without, y_test_pred_without)
test_r2_without = r2_score(y_test_without, y_test_pred_without)

print(f'Temporal CNN-LSTM Validation:\n MAE: {val_mae_without:.4f} \n RMSE: {val_rmse_without:.4f} \n R-squared: {val_r2_without:.4f}')
print(f'Temporal CNN-LSTM Test:\n MAE: {test_mae_without:.4f} \n RMSE: {test_rmse_without:.4f} \n R-squared: {test_r2_without:.4f}')

test_dates = df.index[train_size + val_size:]
compare_without = pd.DataFrame({
    'charged_energy': y_test_without.flatten(),
    'predicted': y_test_pred_without.flatten()}, index=test_dates)

# Group by day
compare_without['day'] = compare_without.index.normalize()
group_without = compare_without.groupby('day')[['charged_energy', 'predicted']].sum().reset_index()
group_without['mae'] = np.abs(group_without['charged_energy'] - group_without['predicted'])

fig, axs = plt.subplots(2, 1, figsize=(12, 6), layout='constrained')

# Actual vs Predicted
axs[0].plot(group_without['day'], group_without['charged_energy'], label='Actual', color='blue')
axs[0].plot(group_without['day'], group_without['predicted'], label='Predicted', color='orange')
axs[0].set_title('SpatioTemporal LSTM: Actual vs Predicted')
axs[0].set_ylabel('Energy Consumption (kWh)')
axs[0].legend()
axs[0].grid(True)
axs[0].xaxis.set_major_locator(mdates.MonthLocator())
axs[0].xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))
axs[0].tick_params(labelbottom=False)

# Daily MAE
axs[1].plot(group_without['day'], group_without['mae'], label='MAE', color='purple')
axs[1].set_xlabel('Date')
axs[1].set_ylabel('Error Score')
axs[1].legend()
axs[1].grid(True)
axs[1].xaxis.set_major_locator(mdates.MonthLocator())
axs[1].xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))
axs[1].tick_params(axis='x', rotation=0)

plt.tight_layout()
plt.savefig('temporal_cnnlstm.png', dpi=300)
plt.show()

group_without['day'] = pd.to_datetime(group_without['day'])
group_without['month'] = group_without['day'].dt.month
peak = group_without[(group_without['month'] >= 6) & (group_without['month'] <= 10)]

plt.figure(figsize=(10, 6))
sns.histplot(peak['mae'], bins=30, kde=True, edgecolor='black', alpha=0.7)
plt.title('Residuals Histogram with KDE (After June)')
plt.xlabel('Residuals (MAE)')
plt.ylabel('Frequency')
plt.grid(True)
plt.savefig('temporal_cnnlstm_residuals.png', dpi=300)
plt.show()

land_types = df['land_types'].iloc[-len(y_test_without):].values

test_data = pd.DataFrame({
    'charged_energy': y_test_without.flatten(),
    'predicted': y_test_pred_without.flatten(),
    'land_types': land_types}, index=df.index[-len(y_test_without):])

test_data['hour'] = test_data.index.hour

land_types = ['commercial', 'construction']
filtered = test_data[test_data['land_types'].isin(land_types)]

group_hourly = (filtered.groupby(['hour', 'land_types'])[['charged_energy', 'predicted']].sum().reset_index())
group_hourly['mae'] = np.abs(group_hourly['charged_energy'] - group_hourly['predicted'])

# Plotting
fig, axs = plt.subplots(2, 2, figsize=(12, 6), sharex=True)
for i, land in enumerate(land_types):
    subset = group_hourly[group_hourly['land_types'] == land]

    axs[0, i].plot(subset['hour'], subset['charged_energy'], label='Actual', marker='o', color='blue')
    axs[0, i].plot(subset['hour'], subset['predicted'], label='Predicted', marker='x', color='orange')
    axs[0, i].set_title(f"{land.capitalize()}")
    axs[0, i].set_xlim(0, 24)
    axs[0, i].set_xticks(np.arange(0, 25, 1))
    if i == 0:
        axs[0, i].set_ylabel('Energy Consumption (kWh)')

    axs[0, i].legend()
    axs[0, i].grid(True)

    axs[1, i].plot(subset['hour'], subset['mae'], label='MAE', marker='o', color='purple')
    axs[1, i].set_xlabel('Hour')
    axs[1, i].set_xlim(0, 24)
    axs[1, i].set_xticks(np.arange(0, 25, 1))

    if i == 0:
        axs[1, i].set_ylabel('Error Score')
    axs[1, i].legend()
    axs[1, i].grid(True)

plt.tight_layout()
plt.savefig('temporal_cnnlstm_by_hour_day.png', dpi=300)
plt.show()

"""**One-sided t-test**"""

from scipy.stats import ttest_rel

errors_no_spatial = [0.8361, 0.8337, 0.8386, 0.8381, 0.8383, 0.8331, 0.8334, 0.8392, 0.8374, 0.8350]
errors_with_spatial = [0.8326, 0.8347, 0.8333, 0.8423, 0.8342, 0.8316, 0.8349, 0.8350, 0.8429, 0.8330]

t_stat, p_value = ttest_rel(errors_with_spatial, errors_no_spatial, alternative='less')
print(f"T-statistic: {t_stat:.4f}")
print(f"P-value: {p_value:.4f}")

df_errors = pd.DataFrame({
    'No Spatial': errors_no_spatial,
    'With Spatial': errors_with_spatial})

df_melted = df_errors.melt(var_name='CNN-LSTM', value_name='Absolute Error')

plt.figure(figsize=(8, 5))
sns.boxplot(x='CNN-LSTM', y='Absolute Error', data=df_melted)
plt.title('Prediction Error Distribution: With vs Without Spatial Features')
plt.grid(True)
plt.tight_layout()
plt.savefig('error_boxplot_cnn.png', dpi=300)
plt.show()

"""**Multi-step Predictions**"""

df = pd.read_csv('/content/feature_data.csv')
df["date"] = pd.to_datetime(df["date"], infer_datetime_format=True, errors='coerce')
df.set_index('date', inplace=True)

X = df.drop(columns=['charged_energy'])
y = df['charged_energy']

# Encode land_types
label_encoder = LabelEncoder()
X['land_types'] = label_encoder.fit_transform(X['land_types'].astype(str))
X_land = np.array(X['land_types'], dtype=np.int32).reshape(-1, 1)
X = X.drop(columns=['land_types'])

# Feature type definitions
numeric_features = ['year', 'temperature', 'dewpoint', 'road_density', 'commercial_density',
                    'residential_density', 'recreation_density', 'highway_proximity',
                    'public_transport_proximity', 'evcs_proximity', 'center_proximity',
                    'parking_density', 'month_sin', 'month_cos', 'hour_sin', 'hour_cos']
binary = ['day_of_week', 'weekend', 'holiday', 'covid', 'time_slot']
for col in binary:
    X[col] = X[col].astype(str)

preprocessor = ColumnTransformer(transformers=[
    ('num', MinMaxScaler(), numeric_features),
    ('cat', OneHotEncoder(handle_unknown='ignore'), binary)])

X_scaled = preprocessor.fit_transform(X)

forecast_horizon = 24
time_steps = 24

X_seq, y_seq, land_seq = [], [], []

for i in range(len(X_scaled) - time_steps - forecast_horizon + 1):
    X_seq.append(X_scaled[i:i + time_steps])
    y_seq.append(y.iloc[i + time_steps:i + time_steps + forecast_horizon].values)
    land_seq.append(X_land[i + time_steps - 1])

X_seq = np.array(X_seq, dtype=np.float32)
y_seq = np.array(y_seq, dtype=np.float32)
land_seq = np.array(land_seq, dtype=np.int32)

train_size = int(len(X_seq) * 0.8)
val_size = int(len(X_seq) * 0.1)

X_train_seq = X_seq[:train_size]
X_val_seq = X_seq[train_size:train_size + val_size]
X_test_seq = X_seq[train_size + val_size:]

y_train = y_seq[:train_size]
y_val = y_seq[train_size:train_size + val_size]
y_test = y_seq[train_size + val_size:]

X_land_train = land_seq[:train_size]
X_land_val = land_seq[train_size:train_size + val_size]
X_land_test = land_seq[train_size + val_size:]

best_params = {
    'filters': 208,
    'kernel_size': 5,
    'lstm_units': 96,
    'dropout': 0.2,
    'learning_rate': 0.0007,
    'optimizer': 'adam'}

if best_params['optimizer'] == "adam":
    optimizer = Adam(learning_rate=best_params['learning_rate'])
elif best_params['optimizer'] == "sgd":
    optimizer = SGD(learning_rate=best_params['learning_rate'])
else:
    optimizer = RMSprop(learning_rate=best_params['learning_rate'])

filters = best_params["filters"]
kernel_size = best_params["kernel_size"]
lstm_units = best_params["lstm_units"]
dropout_rate = best_params["dropout"]
optimizer_name = best_params["optimizer"]
learning_rate = best_params["learning_rate"]

seq_input = Input(shape=(X_train_seq.shape[1], X_train_seq.shape[2]), name='seq_input')
land_input = Input(shape=(1,), dtype='int32', name='land_input')

emb = Embedding(input_dim=np.max(X_land) + 1, output_dim=5)(land_input)
emb = Flatten()(emb)
emb = RepeatVector(X_train_seq.shape[1])(emb)

x = Concatenate()([seq_input, emb])
x = Conv1D(filters=filters // 2, kernel_size=kernel_size, activation='relu', padding='same')(x)
x = Dropout(dropout_rate)(x)
x = Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', padding='same')(x)
x = Dropout(dropout_rate)(x)
x = LSTM(units=lstm_units, activation='relu')(x)
output = Dense(1)(x)

model = Model(inputs=[seq_input, land_input], outputs=output)
model.compile(loss='mae', optimizer=optimizer)
model.summary()

early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

history = model.fit([X_train_seq, X_land_train], y_train,
                    validation_data=([X_val_seq, X_land_val], y_val),
                    epochs=30, batch_size=64,
                    callbacks=[early_stopping], verbose=0)

y_pred_multi = model.predict([X_test_seq, X_land_test], batch_size=64)

if y_pred_multi.shape[1] == 1:
    y_pred_multi = np.tile(y_pred_multi, (1, 24))

mae = mean_absolute_error(y_test, y_pred_multi)
rmse = np.sqrt(mean_squared_error(y_test, y_pred_multi))
r2 = r2_score(y_test, y_pred_multi)

print(f'LSTM Test:\n MAE: {mae:.4f} \n RMSE: {rmse:.4f} \n R-squared: {r2:.4f}')

y_pred_flat = y_pred_multi.flatten()
y_test_flat = y_test.flatten()

base_times = df.index[train_size + val_size + time_steps : train_size + val_size + time_steps + len(y_pred_multi)]
timestamps = []

for base in base_times:
    timestamps.extend([base + pd.Timedelta(hours=i) for i in range(forecast_horizon)])

timestamps = pd.to_datetime(timestamps)

min_len = min(len(y_pred_flat), len(y_test_flat), len(timestamps))
y_pred_flat = y_pred_flat[:min_len]
y_test_flat = y_test_flat[:min_len]
timestamps = timestamps[:min_len]

compare_df = pd.DataFrame({
    'charged_energy': y_test_flat,
    'predicted': y_pred_flat}, index=timestamps)

compare_df['day'] = compare_df.index.normalize()
daily_group = (compare_df.groupby('day')[['charged_energy', 'predicted']].sum() / 20).reset_index()
daily_group['mae'] = np.abs(daily_group['charged_energy'] - daily_group['predicted'])

fig, axs = plt.subplots(2, 1, figsize=(12, 6), layout='constrained')

axs[0].plot(daily_group['day'], daily_group['charged_energy'], label='Actual', color='blue')
axs[0].plot(daily_group['day'], daily_group['predicted'], label='Predicted', color='orange')
axs[0].set_title('LSTM Daily Prediction')
axs[0].set_ylabel('Charged Energy (kWh)')
axs[0].legend()
axs[0].grid(True)
axs[0].xaxis.set_major_locator(mdates.MonthLocator())
axs[0].xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))
axs[0].tick_params(labelbottom=False)

axs[1].plot(daily_group['day'], daily_group['mae'], label='MAE', color='purple')
axs[1].set_xlabel('Date')
axs[1].set_ylabel('Mean Absolute Error (kWh)')
axs[1].legend()
axs[1].grid(True)
axs[1].xaxis.set_major_locator(mdates.MonthLocator())
axs[1].xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))

plt.tight_layout()
plt.savefig('daily_cnnlstm.png', dpi=300)
plt.show()

daily_group['residual'] = np.abs(daily_group['charged_energy'] - daily_group['predicted'])
daily_group['day'] = pd.to_datetime(daily_group['day'])
daily_group['month'] = daily_group['day'].dt.month
high_peak = daily_group[daily_group['month'] >= 6]

plt.figure(figsize=(10, 6))
sns.histplot(high_peak['residual'], bins=30, kde=True, edgecolor='black', alpha=0.7)
plt.title('Histogram of Daily Residuals')
plt.xlabel('Residual (kWh)')
plt.ylabel('Frequency')
plt.grid(True)
plt.tight_layout()
plt.savefig('daily_residual_cnnlstm.png', dpi=300)
plt.show()

df['land_types'] = df['land_types'].str.lower()

train_size = int(len(df) * 0.8)
val_size = int(len(df) * 0.1)
test_data = df.iloc[train_size + val_size:]

min_len = min(len(y_test_flat), len(y_pred_flat), len(test_data))
y_test_flat = y_test_flat[:min_len]
y_pred_flat = y_pred_flat[:min_len]
test_data_trimmed = test_data.iloc[:min_len].copy()

results_df = pd.DataFrame({
    'True Energy': y_test_flat,
    'Predicted Energy': y_pred_flat,
    'land_types': test_data_trimmed['land_types'].values
}, index=test_data_trimmed.index)

results_df.index = pd.to_datetime(results_df.index)
results_df['hour'] = results_df.index.hour

selected_types = ['commercial', 'construction']
results_df = results_df[results_df['land_types'].isin(selected_types)]

grouped = results_df.groupby(['land_types', 'hour']).agg({
    'True Energy': 'sum',
    'Predicted Energy': 'sum'
}).reset_index()
grouped['MAE'] = np.abs(grouped['True Energy'] - grouped['Predicted Energy'])

fig, axs = plt.subplots(2, 2, figsize=(12, 6), sharex=True)

for i, land in enumerate(selected_types):
    subset = grouped[grouped['land_types'] == land]

    # Actual vs Predicted (top row)
    axs[0, i].plot(subset['hour'], subset['True Energy'], label='Actual', marker='o', color='blue')
    axs[0, i].plot(subset['hour'], subset['Predicted Energy'], label='Predicted', marker='x', color='orange')
    axs[0, i].set_title(f"{land.capitalize()}")
    axs[0, i].set_xlim(0, 23)
    axs[0, i].set_xticks(np.arange(0, 24, 1))
    if i == 0:
        axs[0, i].set_ylabel('Energy Consumption (kWh)')
    axs[0, i].legend()
    axs[0, i].grid(True)

    axs[1, i].plot(subset['hour'], subset['MAE'], label='MAE', marker='o', color='purple')
    axs[1, i].set_xlabel('Hour')
    axs[1, i].set_xlim(0, 23)
    axs[1, i].set_xticks(np.arange(0, 24, 1))
    if i == 0:
        axs[1, i].set_ylabel('Error Score')
    axs[1, i].legend()
    axs[1, i].grid(True)

plt.tight_layout()
plt.savefig('24h_pred_cnnlstm_commercial_construction.png', dpi=300)
plt.show()